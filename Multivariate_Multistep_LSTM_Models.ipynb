{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZYw/Um/agI4v9PS73drEA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SenolIsci/ML-Model-Starters/blob/main/Multivariate_Multistep_LSTM_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multivariate LSTM Models\n",
        "Multivariate time series data means data where there is more than one observation for each time step.\n",
        "\n",
        "There are two main models that we may require with multivariate time series data; they are:\n",
        "\n",
        "* Multiple Input Series.\n",
        "* Multiple Parallel Series."
      ],
      "metadata": {
        "id": "cZzWReXAVYt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Input Series\n",
        "A problem may have two or more parallel input time series and an output time series that is dependent on the input time series.\n",
        "\n",
        "The input time series are parallel because each series has an observation at the same time steps.\n",
        "\n",
        "We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series.\n",
        "\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]] \n",
        " ```\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "UF1xsxxtVjc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we chose three input time steps, then the first sample would look as follows:\n",
        "````\n",
        "Input:\n",
        "\n",
        "10, 15\n",
        "20, 25\n",
        "30, 35\n",
        "Output:\n",
        "\n",
        "65\n",
        "````"
      ],
      "metadata": {
        "id": "fViZ_Z41WGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_fsqi_bXR1I",
        "outputId": "1c9441e9-df98-41ca-fb5e-2071e41ecd16"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[206.2547]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ762QFSgv8S",
        "outputId": "24259518-efa2-4a56-e12f-bbda3e8cde5f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_35 (LSTM)              (None, 50)                10600     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,651\n",
            "Trainable params: 10,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Parallel Series\n",
        "An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each.\n",
        "\n",
        "For example, given the data from the previous section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may want to predict the value for each of the three time series for the next time step.\n",
        "\n",
        "This might be referred to as multivariate forecasting.\n",
        "\n",
        "Again, the data must be split into input/output samples in order to train a model.\n",
        "\n",
        "The first sample of this dataset would be:\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15, 25\n",
        "20, 25, 45\n",
        "30, 35, 65\n",
        "Output:\n",
        "\n",
        "40, 45, 85\n",
        "```"
      ],
      "metadata": {
        "id": "41xWWsy3XSG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate output stacked lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=400, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q99fBgQrYRMW",
        "outputId": "0cb1bc2b-e579-46cb-aa67-3e7f9de6b2b6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100.69222 105.74921 206.03606]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8cElt3YgzLx",
        "outputId": "fe79ba82-5363-4cb4-9a61-75f3b2d81a19"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_36 (LSTM)              (None, 3, 100)            41600     \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,303\n",
            "Trainable params: 122,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Step LSTM Models\n",
        "A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting.\n",
        "\n",
        "Specifically, these are problems where the forecast horizon or interval is more than one time step.\n",
        "\n",
        "There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
        "\n",
        "* Vector Output Model\n",
        "* Encoder-Decoder Model"
      ],
      "metadata": {
        "id": "k7RopTWWYRjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with one-step forecasting, a time series used for multi-step time series forecasting must be split into samples with input and output components.\n",
        "\n",
        "Both the input and output components will be comprised of multiple time steps and may or may not have the same number of steps.\n",
        "\n",
        "For example, given the univariate time series:\n",
        "```\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "```\n",
        "We could use the last three time steps as input and forecast the next two time steps.\n",
        "\n",
        "The first sample would look as follows:\n",
        "```\n",
        "Input:\n",
        "\n",
        "[10, 20, 30]\n",
        "Output:\n",
        "\n",
        "[40, 50]\n",
        "```"
      ],
      "metadata": {
        "id": "n4Pe1NwaaJIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Output Model\n",
        "Like other types of neural network models, the LSTM can output a vector directly that can be interpreted as a multi-step forecast.\n",
        "\n",
        "With the number of input and output steps specified in the n_steps_in and n_steps_out variables, we can define a multi-step time-series forecasting model.\n",
        "\n",
        "Any of the presented LSTM model types could be used, such as Vanilla, Stacked, Bidirectional, CNN-LSTM, or ConvLSTM. Below defines a Stacked LSTM for multi-step forecasting."
      ],
      "metadata": {
        "id": "mMte-T1qaiIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate multi-step vector-output stacked lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=50, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAkqjjthbLRM",
        "outputId": "fa147dc2-e352-4b73-92f6-ef42ff71d53c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[121.0854  142.06833]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUxpV4dOg1Fq",
        "outputId": "a6b7af4f-711b-4d48-b261-eb71facf1b4f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_38 (LSTM)              (None, 3, 100)            40800     \n",
            "                                                                 \n",
            " lstm_39 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,402\n",
            "Trainable params: 121,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder-Decoder Model\n",
        "A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.\n",
        "\n",
        "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another.\n",
        "\n",
        "This model can be used for multi-step time series forecasting.\n",
        "\n",
        "As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
        "\n",
        "The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the modelâ€™s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models."
      ],
      "metadata": {
        "id": "DtovElDvbYLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate multi-step encoder-decoder lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(RepeatVector(n_steps_out))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDUVKnfnbmLm",
        "outputId": "9f8b0a31-0c89-4845-8d32-e5e06549e71f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[102.84052 ]\n",
            "  [115.578445]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5EOudyOg2T6",
        "outputId": "f2b98c29-b241-4379-8d88-96660c21f02b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_40 (LSTM)              (None, 100)               40800     \n",
            "                                                                 \n",
            " repeat_vector_2 (RepeatVect  (None, 2, 100)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 2, 100)            80400     \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 2, 1)             101       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,301\n",
            "Trainable params: 121,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multivariate Multi-Step LSTM Models\n",
        "In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting.\n",
        "\n",
        "It is possible to mix and match the different types of LSTM models presented so far for the different problems. This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but it may be a little more challenging.\n",
        "\n",
        "In this section, we will provide short examples of data preparation and modeling for multivariate multi-step time series forecasting as a template to ease this challenge, specifically:\n",
        "\n",
        "* Multiple Input Multi-Step Output.\n",
        "* Multiple Parallel Input and Multi-Step Output."
      ],
      "metadata": {
        "id": "Ir0VfGw5bpa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Input Multi-Step Output\n",
        "There are those multivariate time series forecasting problems where the output series is separate but dependent upon the input time series, and multiple time steps are required for the output series.\n",
        "\n",
        "For example, consider our multivariate time series from a prior section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may use three prior time steps of each of the two input time series to predict two time steps of the output time series.\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15\n",
        "20, 25\n",
        "30, 35\n",
        "Output:\n",
        "\n",
        "65\n",
        "85\n",
        "```"
      ],
      "metadata": {
        "id": "AUt4Ws1VcBuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate multi-step stacked lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out-1\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# covert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4RuBYF2fHb4",
        "outputId": "8932e97e-b34d-4382-8ac6-387043599be3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[187.39598 206.9088 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZYwpnOg44v",
        "outputId": "22e3e3ce-bdad-44d9-d94b-e2ad45a8f7f3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_42 (LSTM)              (None, 3, 100)            41200     \n",
            "                                                                 \n",
            " lstm_43 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,802\n",
            "Trainable params: 121,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Parallel Input and Multi-Step Output\n",
        "A problem with parallel time series may require the prediction of multiple time steps of each time series.\n",
        "\n",
        "For example, consider our multivariate time series from a prior section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may use the last three time steps from each of the three time series as input to the model and predict the next time steps of each of the three time series as output.\n",
        "\n",
        "The first sample in the training dataset would be the following.\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15, 25\n",
        "20, 25, 45\n",
        "30, 35, 65\n",
        "Output:\n",
        "\n",
        "40, 45, 85\n",
        "50, 55, 105\n",
        "```"
      ],
      "metadata": {
        "id": "LyB_2IOxfTi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate multi-step encoder-decoder lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# covert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(RepeatVector(n_steps_out))\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_features)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=300, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesCWWz7fd9q",
        "outputId": "91f8ff2f-5c23-4478-ed98-572ca2bb14f5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 91.03235  95.1714  186.68002]\n",
            "  [100.99406 105.80376 206.58943]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhcLpTvKfpn2",
        "outputId": "2e7e5dd8-e410-4a76-d5d7-2d6667d1974e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_44 (LSTM)              (None, 200)               163200    \n",
            "                                                                 \n",
            " repeat_vector_3 (RepeatVect  (None, 2, 200)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_45 (LSTM)              (None, 2, 200)            320800    \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 2, 3)             603       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 484,603\n",
            "Trainable params: 484,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOTapyS6goGb"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}