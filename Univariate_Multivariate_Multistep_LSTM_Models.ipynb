{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJHfChEaiRN1j0CzymTuSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SenolIsci/ML-Model-Starters/blob/main/Univariate_Multivariate_Multistep_LSTM_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Univariate LSTM Models\n",
        "LSTMs can be used to model univariate time series forecasting problems.\n",
        "\n",
        "These are problems comprised of a single series of observations and a model is required to learn from the series of past observations to predict the next value in the sequence.\n",
        "\n",
        "We will demonstrate a number of variations of the LSTM model for univariate time series forecasting.\n",
        "\n",
        "This section is divided into six parts; they are:\n",
        "\n",
        "* Data Preparation\n",
        "* Vanilla LSTM\n",
        "* Stacked LSTM\n",
        "* Bidirectional LSTM\n",
        "* CNN LSTM\n",
        "* ConvLSTM"
      ],
      "metadata": {
        "id": "kl92FOUhpky5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vanilla LSTM\n",
        "A Vanilla LSTM is an LSTM model that has a single hidden layer of LSTM units, and an output layer used to make a prediction."
      ],
      "metadata": {
        "id": "bGO67OnLOZvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R7fG0qPq2jY",
        "outputId": "58b38d4d-a2e1-4584-c598-009962a805c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102.18906]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulFQA4tNUWBE",
        "outputId": "63eb04e0-11ee-4d19-ba51-a5bdbaf386af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_13 (LSTM)              (None, 50)                10400     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stacked LSTM\n",
        "Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model.\n",
        "\n",
        "An LSTM layer requires a three-dimensional input and LSTMs by default will produce a two-dimensional output as an interpretation from the end of the sequence.\n",
        "\n",
        "We can address this by having the LSTM output a value for each time step in the input data by setting the return_sequences=True argument on the layer. This allows us to have 3D output from hidden LSTM layer as input to the next."
      ],
      "metadata": {
        "id": "9GyVDJkuOonk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate stacked lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a univariate sequence\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Hn5Ez-Ov7v",
        "outputId": "6e8d2783-0560-48b3-e596-4a5f3e671236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.828514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50CDIm2UUmK",
        "outputId": "8201755c-13f7-4c62-92e3-96c68335624b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_14 (LSTM)              (None, 3, 50)             10400     \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 50)                20200     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,651\n",
            "Trainable params: 30,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bidirectional LSTM\n",
        "On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.\n",
        "\n",
        "This is called a Bidirectional LSTM.\n",
        "\n",
        "We can implement a Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional."
      ],
      "metadata": {
        "id": "SgmZpkCJOye5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate bidirectional lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "# split a univariate sequence\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgLqYpGPO5aF",
        "outputId": "a2922d12-1b94-4e67-b8ff-9467c3325e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.81385]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tsG5KYHUTHu",
        "outputId": "4bb2d2e1-6d13-48d3-bb71-4b435d7cb0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 100)              20800     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,901\n",
            "Trainable params: 20,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN LSTM\n",
        "A convolutional neural network, or CNN for short, is a type of neural network developed for working with two-dimensional image data.\n",
        "\n",
        "The CNN can be very effective at automatically extracting and learning features from one-dimensional sequence data such as univariate time series data.\n",
        "\n",
        "A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret. This hybrid model is called a CNN-LSTM.\n",
        "\n",
        "The first step is to split the input sequences into subsequences that can be processed by the CNN model. For example, we can first split our univariate time series data into input/output samples with four steps as input and one as output. Each sample can then be split into two sub-samples, each with two time steps. The CNN can interpret each subsequence of two time steps and provide a time series of interpretations of the subsequences to the LSTM model to process as input.\n",
        "\n",
        "We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. The input data can then be reshaped to have the required structure:\n",
        "\n",
        "[samples, subsequences, timesteps, features]"
      ],
      "metadata": {
        "id": "4JoXBOBQO_Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate cnn lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKPi8deePLk1",
        "outputId": "e08115ef-50f3-49a6-adfb-366024c724a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.39623]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHoRz6S3RO7V",
        "outputId": "902e79b6-c9a2-45a5-b906-10c3a9c17849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_9 (TimeDis  (None, None, 2, 64)      128       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, None, 1, 64)      0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, None, 64)         0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 50)                23000     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,179\n",
            "Trainable params: 23,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ConvLSTM\n",
        "A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly into each LSTM unit.\n",
        "\n",
        "The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with univariate time series forecasting.\n",
        "\n",
        "The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be:\n",
        "\n",
        "[samples, timesteps, rows, columns, features]\n",
        "For our purposes, we can split each sample into subsequences where timesteps will become the number of subsequences, or n_seq, and columns will be the number of time steps for each subsequence, or n_steps. The number of rows is fixed at 1 as we are working with one-dimensional data."
      ],
      "metadata": {
        "id": "iwBjrY6cTjiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate convlstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w99WqYT9UGHj",
        "outputId": "4de5427c-4836-4f16-ea14-ebc30730f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.6798]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_d0nquuUMVW",
        "outputId": "1a0a441a-b724-4716-bc7e-ec47f3929323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, 1, 1, 64)          33536     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,601\n",
            "Trainable params: 33,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multivariate LSTM Models\n",
        "Multivariate time series data means data where there is more than one observation for each time step.\n",
        "\n",
        "There are two main models that we may require with multivariate time series data; they are:\n",
        "\n",
        "* Multiple Input Series.\n",
        "* Multiple Parallel Series."
      ],
      "metadata": {
        "id": "cZzWReXAVYt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Input Series\n",
        "A problem may have two or more parallel input time series and an output time series that is dependent on the input time series.\n",
        "\n",
        "The input time series are parallel because each series has an observation at the same time steps.\n",
        "\n",
        "We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series.\n",
        "\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]] \n",
        " ```\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "UF1xsxxtVjc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we chose three input time steps, then the first sample would look as follows:\n",
        "````\n",
        "Input:\n",
        "\n",
        "10, 15\n",
        "20, 25\n",
        "30, 35\n",
        "Output:\n",
        "\n",
        "65\n",
        "````"
      ],
      "metadata": {
        "id": "fViZ_Z41WGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_fsqi_bXR1I",
        "outputId": "1c9441e9-df98-41ca-fb5e-2071e41ecd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[206.2547]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ762QFSgv8S",
        "outputId": "24259518-efa2-4a56-e12f-bbda3e8cde5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_35 (LSTM)              (None, 50)                10600     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,651\n",
            "Trainable params: 10,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Parallel Series\n",
        "An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each.\n",
        "\n",
        "For example, given the data from the previous section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may want to predict the value for each of the three time series for the next time step.\n",
        "\n",
        "This might be referred to as multivariate forecasting.\n",
        "\n",
        "Again, the data must be split into input/output samples in order to train a model.\n",
        "\n",
        "The first sample of this dataset would be:\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15, 25\n",
        "20, 25, 45\n",
        "30, 35, 65\n",
        "Output:\n",
        "\n",
        "40, 45, 85\n",
        "```"
      ],
      "metadata": {
        "id": "41xWWsy3XSG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate output stacked lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=400, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q99fBgQrYRMW",
        "outputId": "0cb1bc2b-e579-46cb-aa67-3e7f9de6b2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100.69222 105.74921 206.03606]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8cElt3YgzLx",
        "outputId": "fe79ba82-5363-4cb4-9a61-75f3b2d81a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_36 (LSTM)              (None, 3, 100)            41600     \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,303\n",
            "Trainable params: 122,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Step LSTM Models\n",
        "A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting.\n",
        "\n",
        "Specifically, these are problems where the forecast horizon or interval is more than one time step.\n",
        "\n",
        "There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
        "\n",
        "* Vector Output Model\n",
        "* Encoder-Decoder Model"
      ],
      "metadata": {
        "id": "k7RopTWWYRjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with one-step forecasting, a time series used for multi-step time series forecasting must be split into samples with input and output components.\n",
        "\n",
        "Both the input and output components will be comprised of multiple time steps and may or may not have the same number of steps.\n",
        "\n",
        "For example, given the univariate time series:\n",
        "```\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "```\n",
        "We could use the last three time steps as input and forecast the next two time steps.\n",
        "\n",
        "The first sample would look as follows:\n",
        "```\n",
        "Input:\n",
        "\n",
        "[10, 20, 30]\n",
        "Output:\n",
        "\n",
        "[40, 50]\n",
        "```"
      ],
      "metadata": {
        "id": "n4Pe1NwaaJIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Output Model\n",
        "Like other types of neural network models, the LSTM can output a vector directly that can be interpreted as a multi-step forecast.\n",
        "\n",
        "With the number of input and output steps specified in the n_steps_in and n_steps_out variables, we can define a multi-step time-series forecasting model.\n",
        "\n",
        "Any of the presented LSTM model types could be used, such as Vanilla, Stacked, Bidirectional, CNN-LSTM, or ConvLSTM. Below defines a Stacked LSTM for multi-step forecasting."
      ],
      "metadata": {
        "id": "mMte-T1qaiIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate multi-step vector-output stacked lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=50, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAkqjjthbLRM",
        "outputId": "fa147dc2-e352-4b73-92f6-ef42ff71d53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[121.0854  142.06833]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUxpV4dOg1Fq",
        "outputId": "a6b7af4f-711b-4d48-b261-eb71facf1b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_38 (LSTM)              (None, 3, 100)            40800     \n",
            "                                                                 \n",
            " lstm_39 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,402\n",
            "Trainable params: 121,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder-Decoder Model\n",
        "A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.\n",
        "\n",
        "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another.\n",
        "\n",
        "This model can be used for multi-step time series forecasting.\n",
        "\n",
        "As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
        "\n",
        "The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models."
      ],
      "metadata": {
        "id": "DtovElDvbYLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate multi-step encoder-decoder lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(RepeatVector(n_steps_out))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDUVKnfnbmLm",
        "outputId": "9f8b0a31-0c89-4845-8d32-e5e06549e71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[102.84052 ]\n",
            "  [115.578445]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5EOudyOg2T6",
        "outputId": "f2b98c29-b241-4379-8d88-96660c21f02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_40 (LSTM)              (None, 100)               40800     \n",
            "                                                                 \n",
            " repeat_vector_2 (RepeatVect  (None, 2, 100)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 2, 100)            80400     \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 2, 1)             101       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,301\n",
            "Trainable params: 121,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multivariate Multi-Step LSTM Models\n",
        "In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting.\n",
        "\n",
        "It is possible to mix and match the different types of LSTM models presented so far for the different problems. This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but it may be a little more challenging.\n",
        "\n",
        "In this section, we will provide short examples of data preparation and modeling for multivariate multi-step time series forecasting as a template to ease this challenge, specifically:\n",
        "\n",
        "* Multiple Input Multi-Step Output.\n",
        "* Multiple Parallel Input and Multi-Step Output."
      ],
      "metadata": {
        "id": "Ir0VfGw5bpa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Input Multi-Step Output\n",
        "There are those multivariate time series forecasting problems where the output series is separate but dependent upon the input time series, and multiple time steps are required for the output series.\n",
        "\n",
        "For example, consider our multivariate time series from a prior section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may use three prior time steps of each of the two input time series to predict two time steps of the output time series.\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15\n",
        "20, 25\n",
        "30, 35\n",
        "Output:\n",
        "\n",
        "65\n",
        "85\n",
        "```"
      ],
      "metadata": {
        "id": "AUt4Ws1VcBuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate multi-step stacked lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out-1\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# covert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
        "model.add(LSTM(100, activation='relu'))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4RuBYF2fHb4",
        "outputId": "8932e97e-b34d-4382-8ac6-387043599be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[187.39598 206.9088 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZYwpnOg44v",
        "outputId": "22e3e3ce-bdad-44d9-d94b-e2ad45a8f7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_42 (LSTM)              (None, 3, 100)            41200     \n",
            "                                                                 \n",
            " lstm_43 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,802\n",
            "Trainable params: 121,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Parallel Input and Multi-Step Output\n",
        "A problem with parallel time series may require the prediction of multiple time steps of each time series.\n",
        "\n",
        "For example, consider our multivariate time series from a prior section:\n",
        "```\n",
        "[[ 10  15  25]\n",
        " [ 20  25  45]\n",
        " [ 30  35  65]\n",
        " [ 40  45  85]\n",
        " [ 50  55 105]\n",
        " [ 60  65 125]\n",
        " [ 70  75 145]\n",
        " [ 80  85 165]\n",
        " [ 90  95 185]]\n",
        " ```\n",
        "We may use the last three time steps from each of the three time series as input to the model and predict the next time steps of each of the three time series as output.\n",
        "\n",
        "The first sample in the training dataset would be the following.\n",
        "\n",
        "Input:\n",
        "```\n",
        "10, 15, 25\n",
        "20, 25, 45\n",
        "30, 35, 65\n",
        "Output:\n",
        "\n",
        "40, 45, 85\n",
        "50, 55, 105\n",
        "```"
      ],
      "metadata": {
        "id": "LyB_2IOxfTi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate multi-step encoder-decoder lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# covert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(RepeatVector(n_steps_out))\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_features)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=300, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesCWWz7fd9q",
        "outputId": "91f8ff2f-5c23-4478-ed98-572ca2bb14f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 91.03235  95.1714  186.68002]\n",
            "  [100.99406 105.80376 206.58943]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhcLpTvKfpn2",
        "outputId": "2e7e5dd8-e410-4a76-d5d7-2d6667d1974e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_44 (LSTM)              (None, 200)               163200    \n",
            "                                                                 \n",
            " repeat_vector_3 (RepeatVect  (None, 2, 200)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_45 (LSTM)              (None, 2, 200)            320800    \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 2, 3)             603       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 484,603\n",
            "Trainable params: 484,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOTapyS6goGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}