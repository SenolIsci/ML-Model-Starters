<p align = "center" draggable=‚Äùfalse‚Äù ><img src="https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png" 
     width="200px"
     height="auto"/>
</p>

# <h1 align="center" id="heading">:wave: Welcome to the Support Repository for the DeepLearningAI Event: Building with Instruction-Tuned LLMs: A Step-by-Step Guide</h1>

Here are a collection of resources you can use to help fine-tune your LLMs, as well as create a few simple LLM powered applications!

## üó£Ô∏è Slides:

Here are the slides used for the event: [Building with Instruction-Tuned LLMs](https://docs.google.com/presentation/d/1ay-0zRnCJRYPDWJeEPIZ3DFE1lyEf_X2/edit?usp=sharing&ouid=103741980085473523088&rtpof=true&sd=true)

## ü™° Fine-tuning Approaches:

<img src="https://i.imgur.com/iXwCAad.png" 
     height="auto"/>

Instruct-tuning OpenLM's OpenLLaMA on the Dolly-15k Dataset Notebooks:

| Notebook | Purpose | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  **Instruct-tuning Leveraging QLoRA**  | Supervised fine-tuning! | [Here](https://colab.research.google.com/drive/1SRclU2pcgzCkVXpmhKppVbGW4UcCs5xT?usp=sharing) |
|  **Instruct-tuning Leveraging Lit-LLaMA**  | Using Lightning-AI's Lit-LLaMA frame for Supervised fine-tuning  | [Here](https://colab.research.google.com/drive/1a9OaXVFwrVp-OznIXsbzYuhSHr6TLamy?usp=sharing)   |
|  **Natural Language to SQL fine-tuning using Lit-LLaMA**  | Using Lightning-AI's Lit-LLaMA frame for Supervised fine-tuning on the Natural Language to SQL task  | [Here](https://colab.research.google.com/drive/1oE_gsYKST8-LiTgV1ADeXT8l3ktS9kJq?usp=sharing)   |

MarketMail Using BLOOMz Resources:

| Notebook | Purpose | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  **BLOOMz-LoRA Unsupervised Fine-tuning Notebook**  | Fine-tuning BLOOMz with an unsupervised approach using Sythetic Data! | [Here](https://colab.research.google.com/drive/1ARmlaZZaKyAg6HTi57psFLPeh0hDRcPX?usp=sharing) |
|  **Creating Synthetic Data with GPT-3.5-turbo**  | Generate Data for Your Model! | [Here](https://colab.research.google.com/drive/1nsyT9ssUWUWTc_TQ2rykuVtedA7QobA-?usp=sharing)   |

## üèóÔ∏è Converting Models into Applications:

<img src="https://i.imgur.com/NxcHZkj.png" 
     height="auto"/>

| Notebook | Purpose | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  **Open-source LangChain Example**  | Leveraging LangChain to build a Hugging Face ü§ó Powered Application | [Here](https://colab.research.google.com/drive/1nz_P1dG1hpE2WIJ6Y2CKIO4BKhh-vlVH?usp=sharing) |
|  **Open AI LangChain Example**  | Building an Open AI Powered Application | [Here](https://colab.research.google.com/drive/1iwuPo2UjK50cNdkIqbiBWB_zBc7XN5Vl?usp=sharing)   |

## üñ•Ô∏è Demos:

| Demo | Info | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  **Instruct-tuned Chatbot Leveraging QLoRA**  | This demo is currently powered by the Guanaco Model - will be updated once our instruct-tuned model finishes training! | [Here](https://huggingface.co/spaces/FourthBrainGenAI/DeepLearningAIDemoChatBot) |
|  **TalkToMyDoc**  | Query the first Hitch Hiker's Guide book! | [Here](https://huggingface.co/spaces/FourthBrainGenAI/TalkToMyDoc-Hitch-Hikers-Guide)   |
